\chapter{Discussion and Conclusion}
Novel point cloud scenarios within the context of \acrfull{had} systems were generated by injecting a \acrfull{pcd} object from a source scene \acrshort{pcd} into a target scene \acrshort{pcd}. By using the orientation of the prototype in the source scene \acrshort{pcd}, the prototype was transformed into a target location on the target point cloud. After the transformation, a new point cloud for the transformed prototype was calculated and the shadow casted by the newly computed prototype \acrshort{pcd} on the target scene \acrshort{pcd} was observed.

\section{Challenges}

The initial phase of experimental data collection from CARLA posed hurdles due to the necessity of meeting system requirements for running CARLA and ensuring compatibility with all requisite versions of dependent software such as ROS2, carla-ros-brige, and the operating system. Placing the extracted prototype point cloud data (PCD) into a designated target location also presented difficulties. Initial attempts using the \acrfull{icp} registration algorithm proved ineffective, particularly in areas with sparse points in the point cloud. Instead, successful placement of the extracted prototype \acrshort{pcd} was achieved by transforming it based on the centroid of the filtered ground plane. To address the challenge of unknown surfaces of a prototype that are not visible to the LiDAR sensor, the extracted prototype point cloud is rotated during transformation within the target scene PCD. This rotation is determined by utilizing the centroid of the prototype both before and after translation. Additionally, obtaining a realistic point cloud of the prototype that accurately replicated the real LiDAR beam scan patterns at various positions within the target scene \acrfull{roi} posed a challenge. This was addressed by leveraging the points within the target point cloud to simulate the laser beams for raycasting, thereby generating a realistic LiDAR point cloud of the prototype at a desired \acrshort{roi} without requiring knowledge of the LiDAR configuration. Furthermore, accurately calculating the realistic shadow projected by the prototype onto the target ROI of the scene cloud initially proved to be error-prone when using the \acrfull{hpr} algorithm. However, the process was refined by tracking casted rays to the target ROI, facilitating the computation of a realistic shadow projected by the prototype onto the ROI of target scene \acrshort{pcd}.



\section{Future Works}
The project could be improved in various ways.
\begin{itemize}
    \item Extraction of the prototype \acrshort{pcd} from the source scene \acrshort{pcd} is done by using surface variation only. Several other geometric features could be used to remove the false positives. This is required in the case when working with real-world LiDAR data.
    \item By scanning an object from a different angle view and by the point cloud registrations technique, a point cloud representing a complete hollow 3D object could be constructed. Such objects could be rotated in any way in the target location. This results in an increase in the variability of scenarios.
    \item The centroid of points from the remaining points in the \acrshort{roi} on the source scene \acrshort{pcd} is calculated after cropping the prototype \acrshort{pcd}, which is later used in the transformation of the prototype on the target scene \acrshort{pcd}. If the remaining points after filtering the prototype \acrshort{pcd} consist of points from the prototype or higher z-values than the ground plane, then the transformation would be wrong. Eg. the transformed prototype point cloud lies 1 meter above the target ground plane i.e. floating in the air.
    \item Experiment is done on flat surfaces point cloud. Improvements could be made in the future by adding support for non-planar surfaces.
    \item The Prototype \acrshort{pcd} could only be extracted if it is standing on the ground plane point cloud. There could be a scenario where a prototype could be very near to the LiDAR sensor where there is no ground plane \acrshort{pcd}. Because of the field of view of the LiDAR sensor, only the upper region of prototype surface is scanned by the LiDAR scanner. The ground plane where the prototype is situated or the lower region of prototype points is not visible. Current method needs to be updated for extracting such objects as there is no ground plane point cloud to calculate a reference centroid for transformation.
    \item The Raycasting process depends on the original direction of the laser on the target scene \acrshort{pcd}. If the points represented on the target scene \acrshort{pcd} are erroneous, then the resulting raycasted points will be erroneous.
    \item Accurately representing the surface of the prototype \acrshort{pcd} after surface reconstruction would result in a reduced error during raycasting and shadowcasting.
    \item To replicate the behavior of lidar sensors in real-world settings, random dropout, and noise can be introduced.
    \item At present, the intensity of points can be determined by assigning an intensity function to points based on their distance from the origin. However, there is a need to develop methodologies that take into account and preserve the reflective characteristics of the prototype surface.
    \item Currently, manual selection of a region is done for the insertion of the extracted prototype in a desired region of the target scene \acrshort{pcd}. Finding an appropriate region automatically for the insertion of the prototype on the target region of the target scene \acrshort{pcd} could remove the step for manual intervention. If the manual selection of the \acrshort{roi} step is eliminated then by using the pre-saved extracted prototype \acrshort{pcd}, real-time injection on the target scene \acrshort{pcd} could be possible.
    \item In this thesis, the challenge of class imbalance is addressed by leveraging the reuse of existing scenes. However, it is imperative to further investigate methods that accommodate scenarios without the reuse of pre-existing scenes.
\end{itemize}

\section{Conclusion}
Thus, novel scenarios, in the context of \acrfull{had} Systems, were synthesized through LiDAR data augmentation. This involved extracting a prototype point cloud utilizing the geometric features of 3D points in the local neighborhood of the point cloud. The prototype surface was then reconstructed at a designated location within the target scene \acrshort{pcd}, and new point clouds for the prototype were calculated based on the original direction of laser rays in the target scene \acrshort{pcd}. Subsequently, shadows projected by the newly computed prototype \acrshort{pcd} onto the target scene \acrshort{pcd} were determined. Thus, resulting in the creation of a new point cloud representing the altered scene. Evaluation of the approach was conducted by analyzing two point clouds representing identical backgrounds: one with a ground truth prototype (foreground object) and another without. This methodology allowed for the examination of discrepancies between the ground truth and the calculated new point cloud without the necessity of considering differing background point clouds. 

The study effectively tackled the challenge of class imbalance between foreground objects and background scenes within \acrfull{had} systems through an innovative strategy leveraging LiDAR data augmentation. Significantly, this was achieved without the reliance on annotated LiDAR data during prototype extraction and without prior knowledge of the LiDAR characteristics of the target dataset to be augmented. This novel process circumvents the necessity for 3D semantic models or pre-existing CAD models. Furthermore, the augmentation process demonstrated its potential in mitigating deficiencies within scenarios by seamlessly integrating foreground objects into background scenes, thereby generating diverse and novel scenarios. 
The methodology investigated in this study could benefit from improvements in the surface reconstruction phase. By incorporating automated selection of regions within the target scene, the process could facilitate real-time injection of foreground objects and the generation of extensive datasets featuring diverse scenarios, all without requiring manual intervention. Such enhancements hold promise for integration into testing phases aimed at assessing the performance of \acrfull{had} systems, thereby advancing the evaluation of system efficacy.

