\chapter{Discussion and Conclusion}
A new point cloud scene in the context of AD was created by injecting a point cloud object from one source scene cloud to a target cloud. By using the orientation of the prototype of the source scene, the prototype was transformed into a target location on the target point cloud. After the transformation, a new point cloud for the transformed prototype was calculated and the shadow casted by the new prototype cloud on the target scene was observed.
\section{Challenges and Improvements}
The project could be improved in various ways.
\begin{itemize}
    \item Extraction of the prototype from the source scene cloud is done by using surface variation only. Several other geometric features could be used to remove the false positives.
    \item Extracted prototype cloud needs to be rotated on the target scene based on the target location. This is because a lidar sensor captures only the surface information of an object that is facing toward the sensor. Surfaces facing in the opposite direction of lidar sensor information is not available as a laser is not hitting these surfaces.
    \item By scanning an object from a different angle view and by the point cloud registrations technique, a point cloud representing a complete hollow 3D object could be constructed. Such objects could be rotated in any way in the target location. This results in an increase in the variability of scenarios.
    \item The Centroid of points from the remaining points in the region of interest on the source scene cloud after cropping the prototype is calculated, which is later used in the transformation of the prototype on the target scene. If the remaining points after filtering the prototype consist of points from the prototype or higher z-values than the ground plane, then the transformation would be wrong. Eg. the transformed prototype point cloud lies submerged by 1 meter below the target ground plane.
    \item Experiment is done on flat surfaces with point cloud. Improvements could be made in the future by adding support for non-planar surfaces.
    \item The Prototype could only be extracted if it is standing on the ground plane point cloud. There could be a scenario where a prototype could be very near to the lidar sensor where there is no ground plane point cloud. Because of the field of view of the lidar sensor, prototype top surface points and not the ground plane points or lower region of prototype points are visible. Methods need to be developed for extracting such objects as there is no ground plane point cloud to calculate a reference centroid for transformation.
    \item The Raycasting process depends on the original direction of the laser on the target cloud. If the points represented on the target scene cloud are erroneous, then the resulting raycasted points will be erroneous.
    \item Accurately representing the surface of the prototype cloud would result in a reduced error during raycasting and shadowcasting.
    \item Currently, manual selection of a region is done for the insertion of the extracted prototype in a target region of the target scene cloud. Finding an appropriate region for the insertion of the prototype on the target region of the target scene cloud using 3D geometric features like planarity, linearity, etc could remove the step for manual selection of region on the target scene cloud. If the manual selection of the target region step is eliminated then by using the pre-saved extracted prototype, real-time injection on the target scene cloud could be possible.
\end{itemize}

\section{Conclusion}
Hence a new scenario was created by lidar data augmentation. A prototype cloud was extracted by using the geometric feature of 3D points in the point cloud. The prototype surface was reconstructed on a target location of the target cloud and new point clouds for the prototype were calculated based on the original direction of laser rays in the target cloud. Shadow on the target scene was projected, thus creating a point cloud with a new scene. Evaluation of the approach was done by analyzing two point clouds that represent the same background. One point cloud represented a ground truth point cloud where a prototype (foreground object) was present. Another point cloud represented the same background without the prototype. Testing by this methodology lets us test the difference between the ground truth and the calculated new cloud without the need to think about the different background point clouds. The approach experimented with in the thesis could be improved by improving the surface reconstruction step and could be integrated into a testing phase of AD system efficacy.